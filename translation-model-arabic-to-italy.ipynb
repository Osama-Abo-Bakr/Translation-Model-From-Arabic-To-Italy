{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing Library","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install transformers datasets evaluate sacrebleu numpy ","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:21:12.454199Z","iopub.execute_input":"2024-09-01T21:21:12.454550Z","iopub.status.idle":"2024-09-01T21:21:27.779717Z","shell.execute_reply.started":"2024-09-01T21:21:12.454508Z","shell.execute_reply":"2024-09-01T21:21:27.778635Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m761.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nInstalling collected packages: portalocker, sacrebleu, evaluate\nSuccessfully installed evaluate-0.4.2 portalocker-2.10.1 sacrebleu-2.4.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading Library","metadata":{}},{"cell_type":"code","source":"from transformers import MarianTokenizer, MarianMTModel, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\nfrom datasets import load_dataset\nimport evaluate\nimport numpy","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:21:36.731664Z","iopub.execute_input":"2024-09-01T21:21:36.732425Z","iopub.status.idle":"2024-09-01T21:21:55.782370Z","shell.execute_reply.started":"2024-09-01T21:21:36.732386Z","shell.execute_reply":"2024-09-01T21:21:55.781567Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"markdown","source":"\n#### Data: https://huggingface.co/datasets/Helsinki-NLP/news_commentary\n#### Model: https://huggingface.co/Helsinki-NLP/opus-mt-ar-it","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"Helsinki-NLP/news_commentary\", \"ar-it\")\nds = ds.remove_columns('id')\nds","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:21:55.784100Z","iopub.execute_input":"2024-09-01T21:21:55.785227Z","iopub.status.idle":"2024-09-01T21:21:58.007312Z","shell.execute_reply.started":"2024-09-01T21:21:55.785177Z","shell.execute_reply":"2024-09-01T21:21:58.006472Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/26.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21a9f738ebdd4e44bb0820c7cfaee708"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/9.19M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20914e04f1474454b6feb41a577fb26c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/17227 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1095d893f443400fb3de650c2f611310"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 17227\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"ds = ds['train'].train_test_split(train_size=0.8)\nds","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:04.460876Z","iopub.execute_input":"2024-09-01T21:22:04.461775Z","iopub.status.idle":"2024-09-01T21:22:04.508635Z","shell.execute_reply.started":"2024-09-01T21:22:04.461732Z","shell.execute_reply":"2024-09-01T21:22:04.507782Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 13781\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 3446\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Loading Model & Tokenizer","metadata":{}},{"cell_type":"code","source":"checkpoints = 'Helsinki-NLP/opus-mt-ar-it'\nmodel = MarianMTModel.from_pretrained(checkpoints)\ntokenizer = MarianTokenizer.from_pretrained(checkpoints)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:05.199145Z","iopub.execute_input":"2024-09-01T21:22:05.199808Z","iopub.status.idle":"2024-09-01T21:22:10.674055Z","shell.execute_reply.started":"2024-09-01T21:22:05.199771Z","shell.execute_reply":"2024-09-01T21:22:10.673030Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"241be880e3064784b07c0c5a8b76a726"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/309M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02e270cac253451f9db9a6a8784908ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d9a03df23404479805bc74b4510345f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1edbefd4e3c242c583f0dc25c444c65d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e873b67bc603499cbd05880fdbfdd783"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/824k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed78a7385b14bbb82c4b11feb73b6b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e56306fc80f43a19f29a5c821554203"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Make Preprocessing In Text","metadata":{}},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:10.675750Z","iopub.execute_input":"2024-09-01T21:22:10.676076Z","iopub.status.idle":"2024-09-01T21:22:10.682283Z","shell.execute_reply.started":"2024-09-01T21:22:10.676042Z","shell.execute_reply":"2024-09-01T21:22:10.681370Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 13781\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 3446\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"ds['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:10.683425Z","iopub.execute_input":"2024-09-01T21:22:10.683753Z","iopub.status.idle":"2024-09-01T21:22:10.695529Z","shell.execute_reply.started":"2024-09-01T21:22:10.683720Z","shell.execute_reply":"2024-09-01T21:22:10.694668Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'translation': {'ar': 'وفي التحدي الأكثر إلحاحاً الذي يواجه الاتحاد الأوروبي، والذي تفرضه روسيا، سوف يضطر تاسك إلى التوسط في القرارات مع القادة من البلدان التي تشعر بأنها مهددة بشكل مباشر (مثل بلده) وتلك التي تفوق أهمية علاقاتها الاقتصادية مع روسيا أي تهديد لأمن الأوروبي، والذي تشعر بأنه بعيد عنها على أية حال. وعلى جبهة الاقتصاد، يتعين عليه أن يوفق بين أولويات ألمانيا حيث التشغيل الكامل للعمالة وأولويات بلدان مثل اليونان وإيطاليا التي لا تزال واقعة في قبضة الركود ومعدلات البطالة المرتفعة إلى عنان السماء. وقد تكون القدرة على التحدث بشكل مباشر مع أعضاء المجلس، باللغة الإنجليزية في الأغلب، بمثابة التحدي المباشر الأعظم كما اعترف هو شخصيا.',\n  'it': 'Per quanto riguarda la sfida più immediata dell’Ue, posta dalla Russia, Tusk dovrà mediare le decisioni con i leader provenienti dai Paesi che si sentono immediatamente minacciati (come il suo) e con quelli per cui i legami economici con la Russia superano qualsiasi minaccia alla sicurezza europea, fatto che sentono essere remoto. Sul fronte economico, deve riconciliare le priorità della Germania in piena occupazione con quelle di Grecia e Italia, che restano nella morsa della recessione e della disoccupazione.'}}"},"metadata":{}}]},{"cell_type":"code","source":"source_lang = 'ar'\ntarget_lang = 'it'\n\ndef preprocessing(batch):\n    inputs = [example[source_lang] for example in batch['translation']]\n    targets = [example[target_lang] for example in batch['translation']]\n    model_inputs = tokenizer(inputs, text_target=targets, padding=True,\n                             return_tensors='pt', truncation=True)\n    \n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:11.762906Z","iopub.execute_input":"2024-09-01T21:22:11.763828Z","iopub.status.idle":"2024-09-01T21:22:11.769561Z","shell.execute_reply.started":"2024-09-01T21:22:11.763788Z","shell.execute_reply":"2024-09-01T21:22:11.768488Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ds = ds.map(preprocessing, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:12.323600Z","iopub.execute_input":"2024-09-01T21:22:12.324471Z","iopub.status.idle":"2024-09-01T21:22:35.996253Z","shell.execute_reply.started":"2024-09-01T21:22:12.324431Z","shell.execute_reply":"2024-09-01T21:22:35.995274Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13781 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f551d5ef6f1a46f7b3c9d2149e234b8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3446 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d95befb2a7e047a296055f9773dd32b8"}},"metadata":{}}]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:35.997965Z","iopub.execute_input":"2024-09-01T21:22:35.998370Z","iopub.status.idle":"2024-09-01T21:22:36.004300Z","shell.execute_reply.started":"2024-09-01T21:22:35.998335Z","shell.execute_reply":"2024-09-01T21:22:36.003361Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 13781\n    })\n    test: Dataset({\n        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 3446\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# DataCollatorForSeq2Seq","metadata":{}},{"cell_type":"code","source":"data_collector = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoints)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:36.005441Z","iopub.execute_input":"2024-09-01T21:22:36.005744Z","iopub.status.idle":"2024-09-01T21:22:36.035567Z","shell.execute_reply.started":"2024-09-01T21:22:36.005713Z","shell.execute_reply":"2024-09-01T21:22:36.034752Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Create Compute Metrics","metadata":{}},{"cell_type":"code","source":"metric = evaluate.load(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:36.037311Z","iopub.execute_input":"2024-09-01T21:22:36.037660Z","iopub.status.idle":"2024-09-01T21:22:36.676738Z","shell.execute_reply.started":"2024-09-01T21:22:36.037625Z","shell.execute_reply":"2024-09-01T21:22:36.675746Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10ce00e08204766b200364abc2e03cb"}},"metadata":{}}]},{"cell_type":"code","source":"def postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:22:36.678054Z","iopub.execute_input":"2024-09-01T21:22:36.678727Z","iopub.status.idle":"2024-09-01T21:22:36.687856Z","shell.execute_reply.started":"2024-09-01T21:22:36.678682Z","shell.execute_reply":"2024-09-01T21:22:36.686872Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Create Arguments","metadata":{}},{"cell_type":"code","source":"model_args = Seq2SeqTrainingArguments(\n    output_dir=\"./Helsinki-mt-ar-it\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    num_train_epochs=3,\n    fp16=True,\n    warmup_steps=100,\n    logging_steps=100, save_steps=4000\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:25:44.145496Z","iopub.execute_input":"2024-09-01T21:25:44.145909Z","iopub.status.idle":"2024-09-01T21:25:44.184181Z","shell.execute_reply.started":"2024-09-01T21:25:44.145868Z","shell.execute_reply":"2024-09-01T21:25:44.183380Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=model_args,\n    tokenizer=tokenizer,\n    data_collator=data_collector,\n    compute_metrics=compute_metrics,\n    train_dataset=ds['train'],\n    eval_dataset=ds['test']\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:25:44.471045Z","iopub.execute_input":"2024-09-01T21:25:44.471419Z","iopub.status.idle":"2024-09-01T21:25:44.495466Z","shell.execute_reply.started":"2024-09-01T21:25:44.471385Z","shell.execute_reply":"2024-09-01T21:25:44.494559Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:25:46.855242Z","iopub.execute_input":"2024-09-01T21:25:46.856130Z","iopub.status.idle":"2024-09-01T21:43:27.945454Z","shell.execute_reply.started":"2024-09-01T21:25:46.856074Z","shell.execute_reply":"2024-09-01T21:43:27.944568Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2586' max='2586' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2586/2586 17:40, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.744200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.727800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.725900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.830300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.812500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.812200</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.824400</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.822300</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.777200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.752200</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.741400</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.743500</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.743300</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.754600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.766300</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.749000</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.750500</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.720700</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.708100</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.728200</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.711000</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.715300</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.711200</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.707900</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.730600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[63293]], 'forced_eos_token_id': 0}\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2586, training_loss=0.7518522479417983, metrics={'train_runtime': 1060.5428, 'train_samples_per_second': 38.983, 'train_steps_per_second': 2.438, 'total_flos': 2422072866963456.0, 'train_loss': 0.7518522479417983, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Saving Model","metadata":{}},{"cell_type":"code","source":"trainer.save_model(r'/kaggle/working/model')","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:44:57.661316Z","iopub.execute_input":"2024-09-01T21:44:57.661697Z","iopub.status.idle":"2024-09-01T21:44:58.444195Z","shell.execute_reply.started":"2024-09-01T21:44:57.661660Z","shell.execute_reply":"2024-09-01T21:44:58.443052Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[63293]], 'forced_eos_token_id': 0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Make Prediction","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:46:29.877372Z","iopub.execute_input":"2024-09-01T21:46:29.877851Z","iopub.status.idle":"2024-09-01T21:46:29.884658Z","shell.execute_reply.started":"2024-09-01T21:46:29.877804Z","shell.execute_reply":"2024-09-01T21:46:29.883504Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def predict(text, model_checkpoint):\n    print('Input: ', text, '\\n\\n')\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n    outputs = model.generate(inputs, max_new_tokens=300, do_sample=True, top_k=30, top_p=0.95)\n    return \"Output:  \" + tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:46:30.224839Z","iopub.execute_input":"2024-09-01T21:46:30.225537Z","iopub.status.idle":"2024-09-01T21:46:30.232848Z","shell.execute_reply.started":"2024-09-01T21:46:30.225498Z","shell.execute_reply":"2024-09-01T21:46:30.231721Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"text = 'مرحبا'\npredict(text, '/kaggle/working/Helsinki-mt-ar-it/checkpoint-2586')","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:46:30.666118Z","iopub.execute_input":"2024-09-01T21:46:30.666430Z","iopub.status.idle":"2024-09-01T21:46:33.022079Z","shell.execute_reply.started":"2024-09-01T21:46:30.666397Z","shell.execute_reply":"2024-09-01T21:46:33.021060Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Input:  مرحبا \n\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"\"Output:  C'e' nessuno?\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Create Pipeline","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_path = r'/kaggle/working/model'\n# model_path = r'/kaggle/working/Helsinki-mt-ar-it/checkpoint-2586'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n\n# Create a translation pipeline\ntranslation_pipeline = pipeline('translation', model=model, tokenizer=tokenizer)\n\n# Example usage\ninput_text = \"مرحبا\"\ntranslated_text = translation_pipeline(input_text)[0]['translation_text']\n\n# Output the translated text\nprint(translated_text)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:47:19.911047Z","iopub.execute_input":"2024-09-01T21:47:19.911975Z","iopub.status.idle":"2024-09-01T21:47:22.150886Z","shell.execute_reply.started":"2024-09-01T21:47:19.911929Z","shell.execute_reply":"2024-09-01T21:47:22.149966Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"C'e' nessuno?\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Deploy Model","metadata":{}},{"cell_type":"code","source":"!pip install streamlit","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:49:07.926659Z","iopub.execute_input":"2024-09-01T21:49:07.927053Z","iopub.status.idle":"2024-09-01T21:49:23.393510Z","shell.execute_reply.started":"2024-09-01T21:49:07.927014Z","shell.execute_reply":"2024-09-01T21:49:23.392133Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting streamlit\n  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.4.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.8.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: numpy<3,>=1.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<25,>=20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\nRequirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.2.2)\nRequirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (9.5.0)\nRequirement already satisfied: protobuf<6,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (16.1.0)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.32.3)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.1)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.3.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.12.2)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.43)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.4.1)\nCollecting watchdog<5,>=2.1.5 (from streamlit)\n  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\nRequirement already satisfied: narwhals>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.4.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25,>=20->streamlit) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\nDownloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\nSuccessfully installed pydeck-0.9.1 streamlit-1.38.0 watchdog-4.0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import streamlit as st\nfrom transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_path = r'/kaggle/working/model'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n\ntranslation_pipeline = pipeline('translation', model=model, tokenizer=tokenizer)\n\nst.title(\"Translation Model\")\n\ninput_text = st.text_area(\"Enter text to translate:\")\n\nif st.button(\"Translate\"):\n    if input_text:\n        translated_text = translation_pipeline(input_text)\n        st.write(\"Translation:\", translated_text[0]['translation_text'])\n    else:\n        st.write(\"Please enter some text.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-01T21:51:13.527553Z","iopub.execute_input":"2024-09-01T21:51:13.527926Z","iopub.status.idle":"2024-09-01T21:51:13.534296Z","shell.execute_reply.started":"2024-09-01T21:51:13.527888Z","shell.execute_reply":"2024-09-01T21:51:13.533189Z"},"trusted":true},"execution_count":44,"outputs":[]}]}